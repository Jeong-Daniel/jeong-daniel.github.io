---
title: 빅분기 실기대비 이기적 11주차 작업형 1유형 문제풀이
date:   2022-05-12 20:42:30 +0900
categories: [Certificate, 빅데이터분석기사]
tags: [bigdata, data, python, pandas]
---

데이터 출처 :[https://www.kaggle.com/kukuroo3/youtube-episodic-contents-kr](https://www.kaggle.com/kukuroo3/youtube-episodic-contents-kr(참고, 데이터 수정)

데이터 설명 : 유튜브 "공범" 컨텐츠 동영상 정보 ( 10분 간격 수집)

dataurl1 (비디오 정보) = [https://raw.githubusercontent.com/Datamanim/datarepo/main/youtube/videoInfo.csv](https://raw.githubusercontent.com/Datamanim/datarepo/main/youtube/videoInfo.csv)

dataurl2 (참가자 채널 정보)= [https://raw.githubusercontent.com/Datamanim/datarepo/main/youtube/channelInfo.csv](https://raw.githubusercontent.com/Datamanim/datarepo/main/youtube/channelInfo.csv)

데이터 상위 5개 컬럼

![table view](https://user-images.githubusercontent.com/85277660/210562452-6e620c7a-6ae3-408f-ad1c-67a89220aaa3.png)

![img view](https://user-images.githubusercontent.com/85277660/210562478-d90e0179-eed5-4411-a298-543c21b11a92.png)

```py
import pandas as pd
channel =pd.read_csv('https://raw.githubusercontent.com/Datamanim/datarepo/main/youtube/channelInfo.csv')
video =pd.read_csv('https://raw.githubusercontent.com/Datamanim/datarepo/main/youtube/videoInfo.csv')
```

### Q1.  각 데이터의 'ct'컬럼을 시간으로 인식할수 있게 datatype을 변경하고 
video 데이터의 videoname의 각 value 마다 몇개의 데이터씩 가지고 있는지 확인하라
```py
video['ct'] = pd.to_datetime(video['ct'])
print(video.videoname.value_counts())
```

### Q2. 수집된 각 video의 가장 최신화 된 날짜의 viewcount값을 출력하라

```py
video.sort_values(['videoname','ct']).drop_duplicates('videoname',keep='last')[['viewcnt','videoname']]
#videoname, ct로 정렬후 videoname 중복값을 제거, 맨 마지막 행만 남긴다.
```

keep{‘first’, ‘last’, False}, default ‘first’ Determines which duplicates (if any) to keep. - first : Drop duplicates except 

for the first occurrence. - last : Drop duplicates except for the last occurrence. - False : Drop all duplicates.

first로 하면 첫번째 것을 남기는 것이고 last는 마지막것을 남기게 되고 False(기본값)은 모든 중복값을 제거


### Q3. Channel 데이터중 2021-10-03일 이후의 각 채널의 처음 구독자 수(subcnt)를 출력하라

```py
target = channel.loc[(channel.ct > pd.to_datetime('2021-10-03'))].sort_values(['ct','channelname']).drop_duplicates('channelname')
target[['channelname','subcnt']]
```
일단 ct열은 pd.to_datatime으로 형변환을 수행을 합니다. 그리고 비교를 하면 됩니다.

 

### Q4. 각채널의 2021-10-03 03:00:00 ~ 2021-11-01 15:00:00 까지 구독자수 (subcnt) 의 증가량을 구하여라

```
#start, end 시점의 각데이터를 추출하여 merge한 후 subcnt의 차이를 구한다

end = channel.loc[channel.ct.dt.strftime('%Y-%m-%d %H') =='2021-11-01 15']
start = channel.loc[channel.ct.dt.strftime('%Y-%m-%d %H') =='2021-10-03 03']
```

일단 해당하는 열을 가져옵시다. 우리는 모든 정보가 아니라 처음과 마지막 정보만 있으면 됩니다.

```py
end_df = end[['channelname','subcnt']].reset_index(drop=True)
start_df = start[['channelname','subcnt']].reset_index(drop=True)
```
그리고 채널과 subcnt 열만 가진 정보를 새로 가져옵시다.

```py
end_df.columns = ['channelname','end_sub']
start_df.columns = ['channelname','start_sub']
```
구분하기 위해서 columns 이름을 재설정합니다.

```py
tt = pd.merge(start_df,end_df)
tt['del'] = tt['end_sub'] - tt['start_sub']
tt[['channelname','del']]
```
merge는 합병입니다. 중복되는 열을 자동으로 계산해서 합치게 됩니다. 즉 채널이름과 시작 구독자 ,마지막 구독자 3가지 열이 만들어지게 됩니다. 그리고 del이라는 열을 새로 만들어서 집어 넣어주고 다시 불러오면 됩니다.

 
### Q5. 각 비디오는 10분 간격으로 구독자수, 좋아요, 싫어요수, 댓글수가 수집된것으로 알려졌다.

공범 EP1의 비디오정보 데이터중 수집간격이 5분 이하, 20분이상인 데이터 구간( 해당 시점 전,후) 의 시각을 모두 출력하라

```py
import datetime

ep_one = video.loc[video.videoname.str.contains('1')].sort_values('ct').reset_index(drop=True)

ep_one[ (ep_one.ct.diff(1) >=datetime.timedelta(minutes=20)) | \
        (ep_one.ct.diff(1) <=datetime.timedelta(minutes=5))]
answer = ep_one[ep_one.index.isin([720,721,722,723,1635,1636,1637])]
```
개인적으로 이번 문제는 너무 난해해서 넘어갔습니다.

 

### Q6. 각 에피소드의 시작날짜(년-월-일)를 에피소드 이름과 묶어 데이터 프레임으로 만들고 출력하라

```py
start_date = video.sort_values(['ct','videoname']).drop_duplicates('videoname')[['ct','videoname']]
start_date['date'] = start_date.ct.dt.date
answer = start_date[['date','videoname']]
```

### Q7. "공범" 컨텐츠의 경우 19:00시에 공개 되는것으로 알려져있다. 공개된 날의 21시의 viewcnt, ct, videoname 으로 구성된 데이터 프레임을 viewcnt를 내림차순으로 정렬하여 출력하라

```py
video['time']= video.ct.dt.hour
answer = video.loc[video['time'] ==21] \
            .sort_values(['videoname','ct'])\
            .drop_duplicates('videoname') \
            .sort_values('viewcnt',ascending=False)[['videoname','viewcnt','ct']]\
            .reset_index(drop=True)
```

### Q8. video 정보의 가장 최근 데이터들에서 각 에피소드의 싫어요/좋아요 비율을 ratio 컬럼으로 만들고 videoname, ratio로 구성된 데이터 프레임을 ratio를 오름차순으로 정렬하라

```py
target = video.sort_values('ct').drop_duplicates('videoname',keep='last')
target['ratio'] =target['dislikecnt'] / target['likecnt']
answer = target.sort_values('ratio')[['videoname','ratio']].reset_index(drop=True)
answer
```

### Q9. 2021-11-01 00:00:00 ~ 15:00:00까지 각 에피소드별 viewcnt의 증가량을 데이터 프레임으로 만드시오

```py
start = pd.to_datetime("2021-11-01 00:00:00")
end = pd.to_datetime("2021-11-01 15:00:00")

target = video.loc[(video["ct"] >= start) & (video['ct'] <= end)].reset_index(drop=True)

def check(x):
    result = max(x) - min(x)
    return result

answer = target[['videoname','viewcnt']].groupby("videoname").agg(check)
answer
```

### Q10. video 데이터 중에서 중복되는 데이터가 존재한다. 중복되는 각 데이터의 시간대와 videoname 을 구하여라

```py
answer  = video[video.index.isin(set(video.index) -  set(video.drop_duplicates().index))]
answer[['videoname','ct']]
```

내일 금요일은 나머지 12,13,14 주차 1유형 쭉 보고 단답형 2~3번 돌리다가 2유형 한번만 점검하고 시험쳐야 겠습니다.