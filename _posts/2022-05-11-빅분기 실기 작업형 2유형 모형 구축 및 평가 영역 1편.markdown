---
title: 빅분기 실기 작업형 2유형 모형 구축 및 평가 영역 1편
date:   2022-05-11 16:45:41 +0900
categories: [Certificate, 빅데이터분석기사]
tags: [python, bigdata, data, pandas, ml]
---

이번에는 scikit-learn을 바로 써보기 보다 그냥 작업형 2유형이 무엇인지 쭉 살펴보고 넘어갈려고 합니다. 빅분기 카테고리를 만들기도 애매하기는 한데 나중에 정리하던가 하고 일단 시험까지는 scikit-learn 카테고리에다가 쭉 적어 놓겠습니다.


문제 유형 안내부터 봅시다.

---
4. 시험 환경

o 실기시험은 클라우드를 이용한 환경으로 진행

o 일반적인 환경과는 상이한 부분이 있으니 사전에 충분히 확인하여 준비 요망[응시환경 체험](https://dataq.goorm.io/exam/116674/%EC%B2%B4%ED%97%98%ED%95%98%EA%B8%B0/quiz/1)

o 시험은 오픈북이 아니며, 응시환경 및 제공되는 응시안내 자료 외 접속 불가

o 제공언어 : R(3.6), Python(3.6)

o 언어별 제공 패키지 리스트는 첨부 참조(기존 체험환경과 동일)

  * 시험 중 책상 위에는 신분증과 수험표만 허용

o 메모장(windows 보조프로그램) 사용 가능

5. 시험 환경 제한 사항

o 라인별 실행, 그래프 기능, 단축키, 자동완성 기능 미제공

  * 실기 응시환경 내에서 help 함수 이용 가능(예시: help(함수명))

o 코드 실행 시간은 1분으로 제한

o 패키지는 추가 설치할 수 없으며, 제공된 패키지만 이용 가능

o 답안제출

  - 단답형 : 답안 작성 후 “제출” 버튼 클릭, 답안은 영문, 한글 모두 가능

  - 작업형 제1유형 : 마지막 라인에 print(변수명) 명령어로 출력하는 코드를 제출

  - 작업형 제2유형 : 수험번호.csv(003000000.csv) 파일을 생성하는 코드를 작성하여 실행한 후 제출

   * 답안은 중복 제출 가능하며, 마지막 제출 답안이 채점 대상

   * 작업형의 경우 임의의 값을 대입하여 출력하는 경우 0점 처리

   * 작업형 제2유형 채점은 제출된 csv 파일의 평가지표에 따라 구간별 점수를 획득 (예시 : 지표가 0.5~0.6일 경우 10점 등)

   ---

   [패키지 리스트 확인 명령어]

응시환경에서 아래 명령어를 이용하여 설치된 패키지를 확인할 수 있습니다.

import pkg_resources 
import pandas 
OutputDataSet = pandas.DataFrame(sorted([(i.key, i.version) for i in pkg_resources.working_set])) 
print(OutputDataSet)

[패키지 리스트]

0            asn1crypto           0.24.0
1        beautifulsoup4            4.9.3
2               certifi        2018.1.18
3               chardet            3.0.4
4                 cmake     3.18.4.post1
5          cryptography            2.1.4
6                cycler           0.10.0
7                cython          0.29.23
8                  idna              2.6
9                joblib            1.0.1
10              keyring           10.6.0
11         keyrings.alt              3.0
12           kiwisolver            1.3.1
13           matplotlib            3.3.4
14                numpy           1.19.5
15               pandas            1.1.5
16               pillow            8.2.0
17                  pip            9.0.1
18             pycrypto            2.6.1
19            pygobject           3.26.1
20            pyparsing            2.4.7
21           python-apt  1.6.5+ubuntu0.5
22      python-dateutil            2.8.1
23                 pytz           2021.1
24                pyxdg             0.25
25             requests           2.18.4
26         scikit-learn           0.24.1
27                scipy            1.5.4
28        secretstorage            2.3.1
29             selenium          3.141.0
30           setuptools           39.0.1
31                  six           1.11.0
32            soupsieve            2.2.1
33        ssh-import-id              5.7
34        threadpoolctl            2.1.0
35  unattended-upgrades              0.1
36              urllib3             1.22
37                wheel           0.30.0
38              xgboost            1.4.1


---

제약사항 부터 살펴봅시다. 먼저 단축키, 자동완성 기능, 라인별 실행등이 없습니다. 즉 주피터 노트북처럼 개별 실행이 아니라 한번에 전체 분석 코드를 실행 할 수 있어야 합니다. 두번째로 볼 것은 코드 실행 시간은 1분으로 제한됩니다. 즉 기것해야 수천건이지 수만건의 대용량 데이터는 사용하기 어려우며 대용량 서포터벡터머신이나 최적화 하이퍼파라미터 탐색같이 시간이 오래 걸리는 것은 사용하기 어려울 것입니다. 그저 기본값 알고리즘으로 수천건의 데이터를 분석하는것에 그칠 것입니다. 어째 웹크롤링 패키지가 있기는한데 런타임시간 1분 이하인것을 감안하면 아마 신경쓰지 않아도 될 것입니다.

 사용가능한 라이브러리를 보면 scikit-learn과 scipy, sgboost가 있지만 딥러닝이나 텍스트마이닝은 없습니다. 

![img example](https://user-images.githubusercontent.com/85277660/210170565-b911aa2d-5596-4eb2-961b-d9bed29bb39b.png)

유형별 예시에 올라온 두번째 항목 마지막 부분입니다.

 

예측 문제와 수준들을 종합해보면 적절한 데이터 처리와 이를 가지고 머신러닝 알고리즘을 적용하고 csv파일로 저장할 수 있는가? 입니다. 빅데이터분석기사 실기 2회 후기를 살펴봐도 난이도는 되게 쉽게 나왔다는 평이 많습니다.

 

대충 작업형 2의 워크플로우는 다음과 같습니다.

1. 데이터를 가져와서 모든 feature나 일부를 선택하고

2. 정규화 또는 Null or NaN 값에 대해서 전처리를 하고

3. 적절한 알고리즘을 사용

4. 그리고 여유가 있다면 그리드서치나 랜덤서치로 초매개변수 최적화도 해주고 그 값을 적용해볼만 합니다.

5. 마지막으로 제출용 CSV파일 저장

앙상블의 경우 2~3%정도 성능이 향상되기는 하는데 제 생각에는 합격을 당락지을만큼 큰 영향은 주지 못할 것입니다.

 

데이터 몇개 챙겨와서 이정도만 다른 도움 없이 쭉 써내려갈 정도로만 하면 준비가 될 것입니다.

 

남은 1주일동안 Pandas하고 Scikit-learn을 만지는걸로 시간을 보내야 겠습니다. 다음 편에는 2유형 작업편을 한번 해봅시다.